<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ONNX Model Inference</title>
</head>
<body>
    <h1>Upload Image for ONNX Model Inference</h1>
    <input type="file" id="upload" accept="image/*">
    <p id="output"></p>

    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script>
        document.getElementById('upload').addEventListener('change', async (event) => {
            const file = event.target.files[0];
            if (!file) return;

            const img = new Image();
            img.src = URL.createObjectURL(file);
            await img.decode();

            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            canvas.width = 192;
            canvas.height = 192;
            ctx.drawImage(img, 0, 0, canvas.width, canvas.height);

            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const data = imageData.data;

            // Preprocess image data: normalize using the same mean and std as in Python
            const input = new Float32Array(1 * 3 * 192 * 192);
            const mean = [0.485, 0.456, 0.406];
            const std = [0.229, 0.224, 0.225];

            for (let i = 0; i < data.length; i += 4) {
                const idx = i / 4;
                input[idx] = ((data[i] / 255.0) - mean[0]) / std[0];             // R
                input[idx + 192 * 192] = ((data[i + 1] / 255.0) - mean[1]) / std[1]; // G
                input[idx + 2 * 192 * 192] = ((data[i + 2] / 255.0) - mean[2]) / std[2]; // B
            }

            try {
                const session = await ort.InferenceSession.create('./model.onnx');
                const tensor = new ort.Tensor('float32', input, [1, 3, 192, 192]);
                const feeds = { 'input': tensor };  // Adjust 'input' based on your model's input name
                const results = await session.run(feeds);
                
                console.log(results)
                const outputTensor = results['output'];  // Adjust 'output' based on your model's output name
                const outputArray = Array.from(outputTensor.cpuData);

                // Function to find the index of the maximum value
                const argMax = (array) => {
                    return array.reduce((maxIdx, val, idx, arr) => val > arr[maxIdx] ? idx : maxIdx, 0);
                };
                class_labels = ['Angle', 'Front', 'Side']
                // Get the predicted class
                const predictedClass = argMax(outputArray);

                document.getElementById('output').textContent = `Predicted class: ${class_labels[predictedClass]}`;
            } catch (error) {
                console.error('Error running the model:', error);
                document.getElementById('output').textContent = 'Error running the model. Check the console for details.';
            }
        });
    </script>
</body>
</html>
